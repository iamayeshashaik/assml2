{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "df = pd.read_csv(\"C:\\\\Users\\\\tharu\\\\Downloads\\\\HR_comma_sep.csv\")\n",
        "df.head(5)\n",
        "satisfaction_level\tlast_evaluation\tnumber_project\taverage_montly_hours\ttime_spend_company\tWork_accident\tleft\tpromotion_last_5years\tsales\tsalary\n",
        "0\t0.38\t0.53\t2\t157\t3\t0\t1\t0\tsales\tlow\n",
        "1\t0.80\t0.86\t5\t262\t6\t0\t1\t0\tsales\tmedium\n",
        "2\t0.11\t0.88\t7\t272\t4\t0\t1\t0\tsales\tmedium\n",
        "3\t0.72\t0.87\t5\t223\t5\t0\t1\t0\tsales\tlow\n",
        "4\t0.37\t0.52\t2\t159\t3\t0\t1\t0\tsales\tlow\n",
        "df.isnull().sum()\n",
        "satisfaction_level       0\n",
        "last_evaluation          0\n",
        "number_project           0\n",
        "average_montly_hours     0\n",
        "time_spend_company       0\n",
        "Work_accident            0\n",
        "left                     0\n",
        "promotion_last_5years    0\n",
        "sales                    0\n",
        "salary                   0\n",
        "dtype: int64\n",
        "df.shape\n",
        " "
      ],
      "metadata": {
        "id": "fP22WTPUH2qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()\n",
        "satisfaction_level       0\n",
        "last_evaluation          0\n",
        "number_project           0\n",
        "average_montly_hours     0\n",
        "time_spend_company       0\n",
        "Work_accident            0\n",
        "left                     0\n",
        "promotion_last_5years    0\n",
        "sales                    0\n",
        "salary                   0\n",
        "dtype: int64\n",
        "df.describe()\n",
        "satisfaction_level\tlast_evaluation\tnumber_project\taverage_montly_hours\ttime_spend_company\tWork_accident\tleft\tpromotion_last_5years\n",
        "count\t14999.000000\t14999.000000\t14999.000000\t14999.000000\t14999.000000\t14999.000000\t14999.000000\t14999.000000\n",
        "mean\t0.612834\t0.716102\t3.803054\t201.050337\t3.498233\t0.144610\t0.238083\t0.021268\n",
        "std\t0.248631\t0.171169\t1.232592\t49.943099\t1.460136\t0.351719\t0.425924\t0.144281\n",
        "min\t0.090000\t0.360000\t2.000000\t96.000000\t2.000000\t0.000000\t0.000000\t0.000000\n",
        "25%\t0.440000\t0.560000\t3.000000\t156.000000\t3.000000\t0.000000\t0.000000\t0.000000\n",
        "50%\t0.640000\t0.720000\t4.000000\t200.000000\t3.000000\t0.000000\t0.000000\t0.000000\n",
        "75%\t0.820000\t0.870000\t5.000000\t245.000000\t4.000000\t0.000000\t0.000000\t0.000000\n",
        "max\t1.000000\t1.000000\t7.000000\t310.000000\t10.000000\t1.000000\t1.000000\t1.000000"
      ],
      "metadata": {
        "id": "gNuF_WLQI-tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 14999 entries, 0 to 14998\n",
        "Data columns (total 10 columns):\n",
        " #   Column                 Non-Null Count  Dtype  \n",
        "---  ------                 --------------  -----  \n",
        " 0   satisfaction_level     14999 non-null  float64\n",
        " 1   last_evaluation        14999 non-null  float64\n",
        " 2   number_project         14999 non-null  int64  \n",
        " 3   average_montly_hours   14999 non-null  int64  \n",
        " 4   time_spend_company     14999 non-null  int64  \n",
        " 5   Work_accident          14999 non-null  int64  \n",
        " 6   left                   14999 non-null  int64  \n",
        " 7   promotion_last_5years  14999 non-null  int64  \n",
        " 8   sales                  14999 non-null  object \n",
        " 9   salary                 14999 non-null  object \n",
        "dtypes: float64(2), int64(6), object(2)\n",
        "memory usage: 1.1+ MB\n",
        "->Preprocessing and Encode categorical columns using LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['sales'] = le.fit_transform(df['sales'])\n",
        "df['salary'] = le.fit_transform(df['salary'])\n",
        "->Scale numerical columns using StandardScaler\n",
        "\n",
        "scale = StandardScaler()\n",
        "df[['satisfaction_level', 'last_evaluation', 'average_montly_hours', 'time_spend_company']] = scale.fit_transform(df[['satisfaction_level', 'last_evaluation', 'average_montly_hours', 'time_spend_company']])\n",
        "->Split the data into train and test sets"
      ],
      "metadata": {
        "id": "CmC_P4iCJHTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('left', axis=1), df['left'], test_size=0.2, random_state=42)\n",
        "->Building the model\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X_train, y_train)\n",
        "RandomForestClassifier()\n",
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
        "->Make predictions on test set\n",
        "\n",
        "y_pred = rfc.predict(X_test)\n",
        "->Evaluate the model performance\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy :\\n','-'*20, sep=\"\")\n",
        "accuracy\n",
        "Accuracy :\n",
        "--------------------\n",
        "0.988\n",
        "-> Estimate the total compensation to be provided to an employee."
      ],
      "metadata": {
        "id": "QA0qwdszJQd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "->Loading dataset\n",
        "\n",
        "n_df = pd.read_csv(\"C:\\\\Users\\\\tharu\\Downloads\\\\train_set.csv\")\n",
        "n_df.head(5)\n",
        "Year\tOGC\tOG\tDC\tDept\tUC\tUnion\tJF\tJob\tEI\tSalaries\tOvertime\tH/D\tYT\tTotal_Compensation\n",
        "0\t2015\t4\tCommunity Health\tDPH\tPublic Health\t250\tSEIU - Health Workers, Local 1021\tMed Therapy & Auxiliary\tMorgue Attendant\t6725\t12196\t0\t0.00\tCalendar\t16158\n",
        "1\t2013\t4\tCommunity Health\tDPH\tPublic Health\t39\tStationary Engineers, Local 39\tJourneyman Trade\tStationary Engineer\t25058\t74639\t2820\t12703.31\tFiscal\t115784\n",
        "2\t2015\t6\tGeneral Administration & Finance\tASR\tAssessor/Recorder\t21\tProf & Tech Engineers - Miscellaneous, Local 21\tAppraisal & Taxation\tSenior Real Property Appraiser\t46108\t100554\t0\t12424.50\tCalendar\t144708\n",
        "3\t2016\t1\tPublic Protection\tPOL\tPolice\t911\tPolice Officers' Association\tPolice Services\tSergeant 3\t33369\t140164\t52754\t13043.87\tFiscal\t242323\n",
        "4\t2013\t2\tPublic Works, Transportation & Commerce\tHHP\tPUC Hetch Hetchy\t21\tProf & Tech Engineers - Miscellaneous, Local 21\tInformation Systems\tIS Engineer-Journey\t28684\t58813\t0\t7655.28\tCalendar\t82106"
      ],
      "metadata": {
        "id": "THfC2lzQJc6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_df.isnull().sum()\n",
        "Year                   0\n",
        "OGC                    0\n",
        "OG                     0\n",
        "DC                     0\n",
        "Dept                   0\n",
        "UC                     0\n",
        "Union                 36\n",
        "JF                    38\n",
        "Job                    0\n",
        "EI                     0\n",
        "Salaries               0\n",
        "Overtime               0\n",
        "H/D                    0\n",
        "YT                     0\n",
        "Total_Compensation     0\n",
        "dtype: int64\n",
        "n_df.shape\n",
        "(287836, 15)"
      ],
      "metadata": {
        "id": "8R0SK0I5JldZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_df.isna().sum()\n",
        "Year                   0\n",
        "OGC                    0\n",
        "OG                     0\n",
        "DC                     0\n",
        "Dept                   0\n",
        "UC                     0\n",
        "Union                 36\n",
        "JF                    38\n",
        "Job                    0\n",
        "EI                     0\n",
        "Salaries               0\n",
        "Overtime               0\n",
        "H/D                    0\n",
        "YT                     0\n",
        "Total_Compensation     0\n",
        "dtype: int64\n",
        "n_df.drop(['OGC', 'DC', 'UC', 'JF', 'EI', 'YT'], axis=1, inplace= True)\n",
        "n_df.head(5)\n",
        "Year\tOG\tDept\tUnion\tJob\tSalaries\tOvertime\tH/D\tTotal_Compensation\n",
        "0\t2015\tCommunity Health\tPublic Health\tSEIU - Health Workers, Local 1021\tMorgue Attendant\t12196\t0\t0.00\t16158\n",
        "1\t2013\tCommunity Health\tPublic Health\tStationary Engineers, Local 39\tStationary Engineer\t74639\t2820\t12703.31\t115784\n",
        "2\t2015\tGeneral Administration & Finance\tAssessor/Recorder\tProf & Tech Engineers - Miscellaneous, Local 21\tSenior Real Property Appraiser\t100554\t0\t12424.50\t144708\n",
        "3\t2016\tPublic Protection\tPolice\tPolice Officers' Association\tSergeant 3\t140164\t52754\t13043.87\t242323\n",
        "4\t2013\tPublic Works, Transportation & Commerce\tPUC Hetch Hetchy\tProf & Tech Engineers - Miscellaneous, Local 21\tIS Engineer-Journey\t58813\t0\t7655.28\t82106"
      ],
      "metadata": {
        "id": "pY6qS_WGJtdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_df = pd.get_dummies(n_df, columns=['OG', 'Dept', 'Union', 'Job'])\n",
        "n_df.head()\n",
        "Year\tSalaries\tOvertime\tH/D\tTotal_Compensation\tOG_Community Health\tOG_Culture & Recreation\tOG_General Administration & Finance\tOG_General City Responsibilities\tOG_Human Welfare & Neighborhood Development\t...\tJob_Wharfinger 2\tJob_Window Cleaner\tJob_Window Cleaner Supervisor\tJob_Wire Rope Cable Maint Mechanic\tJob_Wire Rope Cable Maint Sprv\tJob_Wireropecable Maint Mech Train\tJob_Worker's Comp Supervisor 1\tJob_Worker's Compensation Adjuster\tJob_X-Ray Laboratory Aide\tJob_Youth Comm Advisor\n",
        "0\t2015\t12196\t0\t0.00\t16158\t1\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "1\t2013\t74639\t2820\t12703.31\t115784\t1\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "2\t2015\t100554\t0\t12424.50\t144708\t0\t0\t1\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "3\t2016\t140164\t52754\t13043.87\t242323\t0\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "4\t2013\t58813\t0\t7655.28\t82106\t0\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "5 rows × 1275 columns"
      ],
      "metadata": {
        "id": "wJDDHdnJJ1ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('Total_Compensation', axis=1), df['Total_Compensation'], test_size=0.2, random_state=42)\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "LinearRegression()\n",
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
        "y_pred = lr.predict(X_test)\n",
        "X_test['Total_Compensation_Predicted'] = y_pred\n",
        "print(X_test[['Salaries', 'Overtime', 'H/D', 'Total_Compensation_Predicted']].head(10))"
      ],
      "metadata": {
        "id": "YyYPLB6UKSy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Salaries  Overtime          H/D  Total_Compensation_Predicted\n",
        "37188      64670     14082  13483.42000                 118267.807932\n",
        "43547      38108         0  10230.58000                  60808.148757\n",
        "128478     54756         0  12918.24848                  86022.045145\n",
        "106956       748         0    269.89000                   -335.654707\n",
        "157292     73379         0  12500.56000                 108432.364359\n",
        "61370      69857         0  12410.67000                 102414.933635\n",
        "285307         0         0     12.86000                   4755.050714\n",
        "131637     60781         0  12801.79000                  92185.768400\n",
        "204983     28955         0   6787.18000                  44796.567884\n",
        "158603    231480         0  12424.50000                 318447.911847\n",
        "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
        "\n",
        "With 79 explanatory variables describing (almost) every aspect of residential homes, build a machine learning model to predict the price of a house\n",
        "\n",
        "Dataset Link: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
      ],
      "metadata": {
        "id": "a4mGtS3uKVbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "train_df = pd.read_csv(\"C:\\\\Users\\\\tharu\\\\Downloads\\\\train.csv\")\n",
        "test_df = pd.read_csv(\"C:\\\\Users\\\\tharu\\\\Downloads\\\\test.csv\")\n",
        "train_df.head(5)"
      ],
      "metadata": {
        "id": "-Q5ZVhOFKdCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(5)\n",
        "Id\tMSSubClass\tMSZoning\tLotFrontage\tLotArea\tStreet\tAlley\tLotShape\tLandContour\tUtilities\t...\tScreenPorch\tPoolArea\tPoolQC\tFence\tMiscFeature\tMiscVal\tMoSold\tYrSold\tSaleType\tSaleCondition\n",
        "0\t1461\t20\tRH\t80.0\t11622\tPave\tNaN\tReg\tLvl\tAllPub\t...\t120\t0\tNaN\tMnPrv\tNaN\t0\t6\t2010\tWD\tNormal\n",
        "1\t1462\t20\tRL\t81.0\t14267\tPave\tNaN\tIR1\tLvl\tAllPub\t...\t0\t0\tNaN\tNaN\tGar2\t12500\t6\t2010\tWD\tNormal\n",
        "2\t1463\t60\tRL\t74.0\t13830\tPave\tNaN\tIR1\tLvl\tAllPub\t...\t0\t0\tNaN\tMnPrv\tNaN\t0\t3\t2010\tWD\tNormal\n",
        "3\t1464\t60\tRL\t78.0\t9978\tPave\tNaN\tIR1\tLvl\tAllPub\t...\t0\t0\tNaN\tNaN\tNaN\t0\t6\t2010\tWD\tNormal\n",
        "4\t1465\t120\tRL\t43.0\t5005\tPave\tNaN\tIR1\tHLS\tAllPub\t...\t144\t0\tNaN\tNaN\tNaN\t0\t1\t2010\tWD\tNormal\n",
        "5 rows × 80 columns\n",
        "\n",
        "X_train = train_df.drop('SalePrice', axis=1)\n",
        "y_train = train_df['SalePrice']"
      ],
      "metadata": {
        "id": "5BzWEr7oKwcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
        "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),('cat', categorical_transformer, categorical_features)])\n",
        "models = [\n",
        "    ('Linear Regression', LinearRegression()),\n",
        "    ('Decision Tree', DecisionTreeRegressor(random_state=42)),\n",
        "    ('Random Forest', RandomForestRegressor(random_state=42)),\n",
        "    ('Gradient Boosting', GradientBoostingRegressor(random_state=42))\n",
        "]\n",
        "for name, model in models:\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_val)\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "    print(f\"{name}: MSE={mse:.2f}, MAE={mae:.2f}, R^2={r2:.2f}\")"
      ],
      "metadata": {
        "id": "o5kpL3qkK3gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Linear Regression: MSE=867133887.70, MAE=18359.50, R^2=0.89\n",
        "Decision Tree: MSE=1748312085.31, MAE=26643.43, R^2=0.77\n",
        "Random Forest: MSE=856245438.81, MAE=17693.30, R^2=0.89\n",
        "Gradient Boosting: MSE=736158439.97, MAE=16832.43, R^2=0.90\n",
        "best_model = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', GradientBoostingRegressor(random_state=42))])\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(test_df)\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(test_df)\n",
        "output = pd.DataFrame({'Id': test_df.Id, 'SalePrice': y_pred})\n",
        "output.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "DVlQaDYcLBzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Obesity is a worldwide problem which causes a lot of serious medical problems. Obesity will be increased, about 45% out of the whole population by 2035. The proportion of morbid obese and the actual costs on healthcare will be increased. Implementation of a system that could estimate the percentage of obese population for particular time duration given the age range, income range, location, high confidence level and low confidence level of obesity, education, gender, the class level, etc. of the population can help in fight against obesity.\n",
        "\n",
        "Build a machine learning model to estimate the percentage of obese population.\n",
        "\n",
        "Dataset Link: https://www.kaggle.com/spittman1248/cdc-data-nutrition-physical-activity-obesity\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "odf = pd.read_csv(\"D:\\\\One Drive Storage\\\\OneDrive\\\\Desktop\\\\DataSets\\\\Nutrition__Physical_Activity__and_Obesity_-_Behavioral_Risk_Factor_Surveillance_System.csv\")\n",
        "odf.head(5)"
      ],
      "metadata": {
        "id": "73fTIXXbLJma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odf.info()\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 53392 entries, 0 to 53391\n",
        "Data columns (total 33 columns):\n",
        " #   Column                      Non-Null Count  Dtype  \n",
        "---  ------                      --------------  -----  \n",
        " 0   YearStart                   53392 non-null  int64  \n",
        " 1   YearEnd                     53392 non-null  int64  \n",
        " 2   LocationAbbr                53392 non-null  object \n",
        " 3   LocationDesc                53392 non-null  object \n",
        " 4   Datasource                  53392 non-null  object \n",
        " 5   Class                       53392 non-null  object \n",
        " 6   Topic                       53392 non-null  object \n",
        " 7   Question                    53392 non-null  object \n",
        " 8   Data_Value_Unit             0 non-null      float64\n",
        " 9   Data_Value_Type             53392 non-null  object \n",
        " 10  Data_Value                  48346 non-null  float64\n",
        " 11  Data_Value_Alt              48346 non-null  float64\n",
        " 12  Data_Value_Footnote_Symbol  5046 non-null   object \n",
        " 13  Data_Value_Footnote         5046 non-null   object \n",
        " 14  Low_Confidence_Limit        48346 non-null  float64\n",
        " 15  High_Confidence_Limit       48346 non-null  float64\n",
        " 16  Sample_Size                 48346 non-null  float64\n",
        " 17  Total                       1907 non-null   object \n",
        " 18  Age(years)                  11438 non-null  object \n",
        " 19  Education                   7628 non-null   object \n",
        " 20  Gender                      3814 non-null   object \n",
        " 21  Income                      13349 non-null  object \n",
        " 22  Race/Ethnicity              15256 non-null  object \n",
        " 23  GeoLocation                 52384 non-null  object \n",
        " 24  ClassID                     53392 non-null  object \n",
        " 25  TopicID                     53392 non-null  object \n",
        " 26  QuestionID                  53392 non-null  object \n",
        " 27  DataValueTypeID             53392 non-null  object \n",
        " 28  LocationID                  53392 non-null  int64  \n",
        " 29  StratificationCategory1     53392 non-null  object \n",
        " 30  Stratification1             53392 non-null  object \n",
        " 31  StratificationCategoryId1   53392 non-null  object "
      ],
      "metadata": {
        "id": "kqQBYMtQLSGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "32  StratificationID1           53392 non-null  object \n",
        "dtypes: float64(6), int64(3), object(24)\n",
        "memory usage: 13.4+ MB\n",
        "odf.shape\n",
        "(53392, 33)\n",
        "odf.isnull().sum()"
      ],
      "metadata": {
        "id": "-TtngBjXLmsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n",
        "Index(['YearStart', 'YearEnd', 'LocationAbbr', 'LocationDesc', 'Datasource',\n",
        "       'Class', 'Topic', 'Question', 'Data_Value_Unit', 'Data_Value_Type',\n",
        "       'Data_Value', 'Data_Value_Alt', 'Data_Value_Footnote_Symbol',\n",
        "       'Data_Value_Footnote', 'Low_Confidence_Limit', 'High_Confidence_Limit ',\n",
        "       'Sample_Size', 'Total', 'Age(years)', 'Education', 'Gender', 'Income',\n",
        "       'Race/Ethnicity', 'GeoLocation', 'ClassID', 'TopicID', 'QuestionID',\n",
        "       'DataValueTypeID', 'LocationID', 'StratificationCategory1',\n",
        "       'Stratification1', 'StratificationCategoryId1', 'StratificationID1'],\n",
        "      dtype='object')\n",
        "odf.drop(['YearEnd', 'Datasource',\n",
        "       'Class', 'Topic', 'Question', 'Data_Value_Unit', 'Data_Value_Type',\n",
        "        'Data_Value_Alt', 'Data_Value_Footnote_Symbol',\n",
        "       'Data_Value_Footnote', 'Low_Confidence_Limit', 'High_Confidence_Limit ',\n",
        "       'Total', 'Gender', 'GeoLocation', 'ClassID', 'TopicID', 'QuestionID',\n",
        "       'DataValueTypeID', 'StratificationCategory1',\n",
        "       'Stratification1', 'StratificationCategoryId1', 'StratificationID1'], axis = 1, inplace=True)\n",
        "odf.head(5)"
      ],
      "metadata": {
        "id": "hu-TXtAJLrHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odf.columns\n",
        "Index(['YearStart', 'LocationAbbr', 'LocationDesc', 'Data_Value',\n",
        "       'Sample_Size', 'Age(years)', 'Education', 'Income', 'Race/Ethnicity',\n",
        "       'LocationID'],\n",
        "      dtype='object')\n",
        "odf.info()\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 53392 entries, 0 to 53391\n",
        "Data columns (total 10 columns):\n",
        " #   Column          Non-Null Count  Dtype  \n",
        "---  ------          --------------  -----  \n",
        " 0   YearStart       53392 non-null  int64  \n",
        " 1   LocationAbbr    53392 non-null  object \n",
        " 2   LocationDesc    53392 non-null  object \n",
        " 3   Data_Value      48346 non-null  float64\n",
        " 4   Sample_Size     48346 non-null  float64\n",
        " 5   Age(years)      11438 non-null  object \n",
        " 6   Education       7628 non-null   object \n",
        " 7   Income          13349 non-null  object \n",
        " 8   Race/Ethnicity  15256 non-null  object \n",
        " 9   LocationID      53392 non-null  int64  \n",
        "dtypes: float64(2), int64(2), object(6)\n",
        "memory usage: 4.1+ MB\n",
        "odf.isna().sum()"
      ],
      "metadata": {
        "id": "nE74EKsELxq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odf.duplicated().sum()\n",
        "odf.drop_duplicates()\n",
        "YearStart\tLocationAbbr\tLocationDesc\tData_Value\tSample_Size\tAge(years)\tEducation\tIncome\tRace/Ethnicity\tLocationID\n",
        "0\t2011\tAL\tAlabama\t32.0\t7304.0\tNaN\tNaN\tNaN\tNaN\t1\n",
        "1\t2011\tAL\tAlabama\t32.3\t2581.0\tNaN\tNaN\tNaN\tNaN\t1\n",
        "2\t2011\tAL\tAlabama\t31.8\t4723.0\tNaN\tNaN\tNaN\tNaN\t1\n",
        "3\t2011\tAL\tAlabama\t33.6\t1153.0\tNaN\tLess than high school\tNaN\tNaN\t1\n",
        "4\t2011\tAL\tAlabama\t32.8\t2402.0\tNaN\tHigh school graduate\tNaN\tNaN\t1\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "53382\t2016\tVI\tVirgin Islands\t13.3\t212.0\tNaN\tNaN\t$75,000 or greater\tNaN\t78\n",
        "53383\t2016\tVI\tVirgin Islands\t25.3\t137.0\tNaN\tNaN\tData not reported\tNaN\t78\n",
        "53384\t2016\tVI\tVirgin Islands\t18.3\t154.0\tNaN\tNaN\tNaN\tNon-Hispanic White\t78\n",
        "53385\t2016\tVI\tVirgin Islands\t24.1\t820.0\tNaN\tNaN\tNaN\tNon-Hispanic Black\t78\n",
        "53386\t2016\tVI\tVirgin Islands\t30.3\t178.0\tNaN\tNaN\tNaN\tHispanic\t78\n",
        "49183 rows × 10 columns"
      ],
      "metadata": {
        "id": "I1Y_YLF8L4pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odf.drop([\"Age(years)\"], axis=1, inplace= True)\n",
        "odf.drop([\"Education\"], axis=1, inplace= True)\n",
        "import seaborn as sns\n",
        "sns.heatmap(odf.corr(), cmap= 'Blues')\n",
        "C:\\Users\\tharu\\AppData\\Local\\Temp\\ipykernel_11084\\281234637.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
        "  sns.heatmap(odf.corr(), cmap= 'Blues')\n",
        "<AxesSubplot: >\n"
      ],
      "metadata": {
        "id": "hJVhxBiUL-9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odf.columns\n",
        "Index(['YearStart', 'LocationAbbr', 'LocationDesc', 'Data_Value',\n",
        "       'Sample_Size', 'Income', 'Race/Ethnicity', 'LocationID'],\n",
        "      dtype='object')\n",
        "odf.info()\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 53392 entries, 0 to 53391\n",
        "Data columns (total 8 columns):\n",
        " #   Column          Non-Null Count  Dtype  \n",
        "---  ------          --------------  -----  \n",
        " 0   YearStart       53392 non-null  int64  \n",
        " 1   LocationAbbr    53392 non-null  object \n",
        " 2   LocationDesc    53392 non-null  object \n",
        " 3   Data_Value      48346 non-null  float64\n",
        " 4   Sample_Size     48346 non-null  float64\n",
        " 5   Income          13349 non-null  object \n",
        " 6   Race/Ethnicity  15256 non-null  object \n",
        " 7   LocationID      53392 non-null  int64  \n",
        "dtypes: float64(2), int64(2), object(4)\n",
        "memory usage: 3.3+ MB\n",
        "odf['Sample_Size'] = odf['Sample_Size'].fillna(odf['Sample_Size'].mean())\n",
        "x = odf[['YearStart', 'LocationID','Sample_Size']]\n",
        "y = odf['Data_Value']\n",
        "y = y.fillna(y.mean())"
      ],
      "metadata": {
        "id": "3nWrRbbqMUqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.isna().sum()\n",
        "YearStart      0\n",
        "LocationID     0\n",
        "Sample_Size    0\n",
        "dtype: int64\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "X_train.head(3)\n",
        "YearStart\tLocationID\tSample_Size\n",
        "27567\t2013\t44\t787.0\n",
        "35683\t2015\t12\t2088.0\n",
        "1414\t2011\t4\t6105.0\n",
        "y_train.head()\n",
        "27567    48.9\n",
        "35683    42.2\n",
        "1414     38.0\n",
        "22401    46.4\n",
        "52430    32.6"
      ],
      "metadata": {
        "id": "608k69_ZMWSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-IdpEI9MpMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Name: Data_Value, dtype: float64\n",
        "std_scaler=StandardScaler().fit(X_train) \n",
        "X_train_scaled=std_scaler.transform(X_train)\n",
        "X_test_scaled=std_scaler.transform(X_test)\n",
        "import statsmodels.api as sm\n",
        "X_train_const_scaled = sm.add_constant(X_train_scaled) \n",
        "model = sm.OLS(y_train, X_train_const_scaled).fit()\n",
        "predictions_train = model.predict(X_train_const_scaled)\n",
        "X_test_const_scaled = sm.add_constant(X_test_scaled)\n",
        "predictions_test = model.predict(X_test_const_scaled) \n",
        "print_model = model.summary()\n",
        "print(print_model)\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:             Data_Value   R-squared:                       0.000\n",
        "Model:                            OLS   Adj. R-squared:                  0.000\n",
        "Method:                 Least Squares   F-statistic:                     1.806\n",
        "Date:                Sat, 25 Mar 2023   Prob (F-statistic):              0.144\n",
        "Time:                        13:09:23   Log-Likelihood:            -1.3823e+05\n",
        "No. Observations:               37374   AIC:                         2.765e+05\n",
        "Df Residuals:                   37370   BIC:                         2.765e+05\n",
        "Df Model:                           3                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "=============================================================================="
      ],
      "metadata": {
        "id": "a_Aip8UTMdhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "              coef    std err          t      P>|t|      [0.025      0.975]\n",
        "------------------------------------------------------------------------------\n",
        "const         31.1542      0.051    616.258      0.000      31.055      31.253\n",
        "x1            -0.0828      0.051     -1.636      0.102      -0.182       0.016\n",
        "x2            -0.0265      0.051     -0.518      0.604      -0.127       0.074\n",
        "x3            -0.0748      0.051     -1.461      0.144      -0.175       0.026\n",
        "==============================================================================\n",
        "Omnibus:                     1783.064   Durbin-Watson:                   1.978\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2338.752\n",
        "Skew:                           0.480   Prob(JB):                         0.00\n",
        "Kurtosis:                       3.763   Cond. No.                         1.18\n",
        "==============================================================================\n",
        "\n",
        "Notes:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "predictions_test"
      ],
      "metadata": {
        "id": "oGykTHznMvVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.rsquared_adj\n",
        "6.472266177293129e-05\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "model.coef_\n",
        "array([-4.88459980e-02, -1.57611918e-03, -3.93981309e-06])\n",
        "model.intercept_\n",
        "129.5581730953405\n",
        "model.score(X_test_scaled,y_test)\n",
        "C:\\Users\\tharu\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
        "  warnings.warn(\n",
        "-102.95275555662994\n",
        "y_pred=model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "x2endcuWNGlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test_scaled)\n",
        "C:\\Users\\tharu\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
        "  warnings.warn(\n",
        "result=pd.DataFrame({\"y_test\":y_test,\"y_pred\":y_pred})\n",
        "result\n",
        "y_test\ty_pred\n",
        "14003\t49.600000\t129.566985\n",
        "2471\t28.600000\t129.568764\n",
        "3625\t31.156681\t129.626109\n",
        "53321\t33.400000\t129.476613\n",
        "937\t25.900000\t129.597858\n",
        "...\t...\t...\n",
        "28655\t19.200000\t129.622552\n",
        "50219\t35.500000\t129.477549\n",
        "43217\t31.156681\t129.507953\n",
        "48668\t34.400000\t129.505426\n",
        "41023\t50.600000\t129.509358"
      ],
      "metadata": {
        "id": "SZr_Y_XSNI5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "16018 rows × 2 columns"
      ],
      "metadata": {
        "id": "AG4oj_7qNQ3A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}